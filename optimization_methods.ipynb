{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShovalBenjer/Algorithms_DynamicProgramming_Codechef_Competition_Submissions/blob/main/optimization_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**\"KKT כופלי לגראנז' ותנאי\"**\n",
        "\n",
        "**עמוד 16 **"
      ],
      "metadata": {
        "id": "8qKgJsSYzaEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import libraries and define symbols\n",
        "# -------------------------------------------\n",
        "# Import sympy for symbolic computations\n",
        "import sympy as sp\n",
        "\n",
        "# Define the decision variables x, y, z and the Lagrange multipliers lambda and mu.\n",
        "x, y, z = sp.symbols('x y z', real=True)\n",
        "lambda_sym, mu_sym = sp.symbols('lambda mu', real=True)\n",
        "\n",
        "# Define the objective function f(x, y, z) = x^2 + y^2 + z^2.\n",
        "f = x**2 + y**2 + z**2\n",
        "\n",
        "# Define the constraints:\n",
        "# Constraint g: x^2 + y^2 - z^2 = 0\n",
        "g = x**2 + y**2 - z**2\n",
        "# Constraint h: x - 2z - 3 = 0\n",
        "h = x - 2*z - 3\n",
        "\n",
        "# Display the defined functions\n",
        "print(\"Objective function f(x,y,z):\", f)\n",
        "print(\"Constraint g(x,y,z) = x^2 + y^2 - z^2:\", g, \"= 0\")\n",
        "print(\"Constraint h(x,y,z) = x - 2z - 3:\", h, \"= 0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibG0mYuEkjKL",
        "outputId": "3e6055e0-18eb-4ce6-c3f7-baa1bb37f9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objective function f(x,y,z): x**2 + y**2 + z**2\n",
            "Constraint g(x,y,z) = x^2 + y^2 - z^2: x**2 + y**2 - z**2 = 0\n",
            "Constraint h(x,y,z) = x - 2z - 3: x - 2*z - 3 = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Formulate the Lagrangian and state the necessary KKT (Lagrange) conditions.\n",
        "# -----------------------------------------------------------------------------------\n",
        "# The Lagrangian L(x,y,z, lambda, mu) is defined as:\n",
        "#   L(x,y,z,lambda,mu) = f(x,y,z) + lambda * g(x,y,z) + mu * h(x,y,z)\n",
        "#\n",
        "# For optimality, the KKT conditions require:\n",
        "#   1. Stationarity: The partial derivatives of L with respect to x, y, and z are zero.\n",
        "#      (i.e., ∂L/∂x = 0, ∂L/∂y = 0, ∂L/∂z = 0)\n",
        "#   2. Primal feasibility: The constraints g(x,y,z)=0 and h(x,y,z)=0 must be satisfied.\n",
        "#\n",
        "# Note: Since we have only equality constraints, we do not need to check complementary slackness.\n",
        "\n",
        "# Define the Lagrangian:\n",
        "L = f + lambda_sym * g + mu_sym * h\n",
        "\n",
        "# Compute the partial derivatives of L with respect to x, y, and z:\n",
        "dL_dx = sp.diff(L, x)\n",
        "dL_dy = sp.diff(L, y)\n",
        "dL_dz = sp.diff(L, z)\n",
        "\n",
        "# Display the derivatives (Stationarity conditions must be set equal to zero):\n",
        "print(\"Stationarity Conditions:\")\n",
        "print(\"∂L/∂x =\", sp.simplify(dL_dx), \"== 0\")\n",
        "print(\"∂L/∂y =\", sp.simplify(dL_dy), \"== 0\")\n",
        "print(\"∂L/∂z =\", sp.simplify(dL_dz), \"== 0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9DG6wkXrdM-",
        "outputId": "98d85980-2f9f-44a7-8052-da87c8c813c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stationarity Conditions:\n",
            "∂L/∂x = 2*lambda*x + mu + 2*x == 0\n",
            "∂L/∂y = 2*y*(lambda + 1) == 0\n",
            "∂L/∂z = -2*lambda*z - 2*mu + 2*z == 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Write down the full system of equations.\n",
        "# ------------------------------------------------\n",
        "# The complete system consists of:\n",
        "#\n",
        "# 1. ∂L/∂x = 0:  2x + 2λ x + μ = 0   ==>   2x*(1+λ) + μ = 0   [Equation (1)]\n",
        "# 2. ∂L/∂y = 0:  2y + 2λ y = 0       ==>   2y*(1+λ) = 0       [Equation (2)]\n",
        "# 3. ∂L/∂z = 0:  2z - 2λ z - 2μ = 0   ==>   2z*(1-λ) - 2μ = 0  [Equation (3)]\n",
        "# 4. Primal feasibility: g(x,y,z) = x^2 + y^2 - z^2 = 0    [Equation (4)]\n",
        "# 5. Primal feasibility: h(x,y,z) = x - 2z - 3 = 0         [Equation (5)]\n",
        "#\n",
        "# We now solve this system for x, y, z, λ (lambda_sym), and μ (mu_sym).\n",
        "\n",
        "# Collect all the equations:\n",
        "eq1 = sp.Eq(2*x*(1+lambda_sym) + mu_sym, 0)       # Equation (1)\n",
        "eq2 = sp.Eq(2*y*(1+lambda_sym), 0)                # Equation (2)\n",
        "eq3 = sp.Eq(2*z*(1-lambda_sym) - 2*mu_sym, 0)      # Equation (3)\n",
        "eq4 = sp.Eq(x**2 + y**2 - z**2, 0)                # Equation (4)\n",
        "eq5 = sp.Eq(x - 2*z - 3, 0)                       # Equation (5)\n",
        "\n",
        "# Display the system of equations for clarity:\n",
        "equations = [eq1, eq2, eq3, eq4, eq5]\n",
        "print(\"System of Equations:\")\n",
        "for i, eq in enumerate(equations, start=1):\n",
        "    sp.pretty_print(eq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYVOU5hQrfd9",
        "outputId": "61b54bfb-a4f7-42dc-e083-8269b319b646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System of Equations:\n",
            "μ + 2⋅x⋅(λ + 1) = 0\n",
            "2⋅y⋅(λ + 1) = 0\n",
            "-2⋅μ + 2⋅z⋅(1 - λ) = 0\n",
            " 2    2    2    \n",
            "x  + y  - z  = 0\n",
            "x - 2⋅z - 3 = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Solve the system of equations.\n",
        "# ----------------------------------------\n",
        "# We solve the equations with sp.solve. There may be more than one candidate solution.\n",
        "# When solving, we state explicitly the conditions encountered.\n",
        "#\n",
        "# Note on Equation (2): 2y*(1+λ)=0\n",
        "# This implies that either y = 0 OR (1+λ)=0.\n",
        "# We will see that the (1+λ)=0 branch leads to inconsistency with the other constraints,\n",
        "# so the viable branch is y = 0.\n",
        "\n",
        "solution_candidates = sp.solve(equations, (x, y, z, lambda_sym, mu_sym), dict=True)\n",
        "print(\"Solution Candidates:\")\n",
        "sp.pprint(solution_candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPdsbF8Wrim-",
        "outputId": "e4c396db-3650-477a-fb0c-bf9dfd543f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution Candidates:\n",
            "[{λ: -3, μ: -12, x: -3, y: 0, z: -3}, {λ: -1/3, μ: -4/3, x: 1, y: 0, z: -1}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Analyze the candidate solutions and verify optimality conditions.\n",
        "# ------------------------------------------------------------------------\n",
        "# The two candidate solutions from the solver are:\n",
        "#\n",
        "# Candidate 1:\n",
        "#   x = -3, y = 0, z = -3, λ = -3, μ = -12\n",
        "#\n",
        "# Candidate 2:\n",
        "#   x = 1,  y = 0, z = -1, λ = -1/3, μ = -4/3\n",
        "#\n",
        "# Both candidates satisfy the stationarity conditions and the constraints.\n",
        "#\n",
        "# Now, we determine which one minimizes the objective function f(x, y, z).\n",
        "\n",
        "# Define the objective function for evaluation:\n",
        "f_func = sp.lambdify((x, y, z), f, 'numpy')\n",
        "\n",
        "# Evaluate the objective function at each candidate:\n",
        "f_val_candidate1 = f.subs({x: -3, y: 0, z: -3})\n",
        "f_val_candidate2 = f.subs({x: 1, y: 0, z: -1})\n",
        "\n",
        "print(\"Objective function values:\")\n",
        "print(\"Candidate 1 (x=-3, y=0, z=-3): f =\", f_val_candidate1)  # f = (-3)^2 + 0 + (-3)^2 = 9 + 9 = 18\n",
        "print(\"Candidate 2 (x=1, y=0, z=-1): f =\", f_val_candidate2)    # f = 1 + 0 + 1 = 2\n",
        "\n",
        "# Clearly, f = 2 is the lower value.\n",
        "#\n",
        "# Therefore, Candidate 2 is the minimum solution.\n",
        "\n",
        "# For completeness, we list the Lagrange multipliers (λ and μ) for Candidate 2:\n",
        "lambda_candidate2 = -sp.Rational(1, 3)\n",
        "mu_candidate2 = -sp.Rational(4, 3)\n",
        "\n",
        "print(\"\\nFinal Optimal Solution (Minimizer):\")\n",
        "print(\"x =\", 1, \"   # Label: min\")\n",
        "print(\"y =\", 0, \"   # Label: min\")\n",
        "print(\"z =\", -1, \"  # Label: min\")\n",
        "print(\"λ (lambda) =\", lambda_candidate2)\n",
        "print(\"μ (mu) =\", mu_candidate2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6BrFy_BroaC",
        "outputId": "4a71ab13-691a-44a9-cc37-f3e6b78300a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objective function values:\n",
            "Candidate 1 (x=-3, y=0, z=-3): f = 18\n",
            "Candidate 2 (x=1, y=0, z=-1): f = 2\n",
            "\n",
            "Final Optimal Solution (Minimizer):\n",
            "x = 1    # Label: min\n",
            "y = 0    # Label: min\n",
            "z = -1   # Label: min\n",
            "λ (lambda) = -1/3\n",
            "μ (mu) = -4/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Summarize the Final Results in a Clear, Human-Readable Format.\n",
        "# -----------------------------------------------------------------------\n",
        "# Final Outcome:\n",
        "#\n",
        "# After solving the KKT conditions (stationarity + feasibility), we have two candidate solutions.\n",
        "#\n",
        "# Candidate 1:\n",
        "#   x = -3, y = 0, z = -3, with f = 18\n",
        "#   (Lagrange multipliers: λ = -3, μ = -12)\n",
        "#\n",
        "# Candidate 2:\n",
        "#   x = 1, y = 0, z = -1, with f = 2\n",
        "#   (Lagrange multipliers: λ = -1/3, μ = -4/3)\n",
        "#\n",
        "# Since our goal is to minimize f(x,y,z), the optimal (minimal) solution is Candidate 2.\n",
        "#\n",
        "# Final Answer (Optimal Minimizer):\n",
        "#   x = 1, y = 0, z = -1\n",
        "#\n",
        "# Additionally, for transparency, the multipliers at the optimal solution are:\n",
        "#   λ = -1/3, μ = -4/3\n",
        "#\n",
        "# All KKT conditions have been explicitly met:\n",
        "#   - Stationarity: ∂L/∂x, ∂L/∂y, and ∂L/∂z equal zero at the candidate point.\n",
        "#   - Primal feasibility: Both constraints are satisfied at (1, 0, -1).\n",
        "#\n",
        "# The final solution has been labeled as 'min' since it minimizes the objective function.\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(\"The optimal solution that minimizes f(x, y, z) = x^2 + y^2 + z^2 is:\")\n",
        "print(\"x = 1 (min), y = 0 (min), z = -1 (min)\")\n",
        "print(\"With Lagrange multipliers: λ =\", lambda_candidate2, \", μ =\", mu_candidate2)\n",
        "print(\"Minimum objective function value: f = 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9-OGIalrrF3",
        "outputId": "c3599ee2-8f60-4b33-bead-7113d18e7abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "The optimal solution that minimizes f(x, y, z) = x^2 + y^2 + z^2 is:\n",
            "x = 1 (min), y = 0 (min), z = -1 (min)\n",
            "With Lagrange multipliers: λ = -1/3 , μ = -4/3\n",
            "Minimum objective function value: f = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**\"שיטות חיפוש במרחב רב מימדי\"**\n",
        "\n",
        "**עמוד 38**"
      ],
      "metadata": {
        "id": "pvH1XTUcykAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries and Define the Objective Function and Its Gradient\n",
        "# -----------------------------------------------------------------------------\n",
        "# In this step, we import necessary libraries and define:\n",
        "#   - The objective function f(x1, x2)\n",
        "#   - Its gradient (partial derivatives with respect to x1 and x2)\n",
        "#\n",
        "# The function is:\n",
        "#   f(x1, x2) = (3/2)*x1^2 + (1/2)*x2^2 - x1*x2 - 2*x1\n",
        "#\n",
        "# The gradient is computed as:\n",
        "#   ∂f/∂x1 = 3*x1 - x2 - 2\n",
        "#   ∂f/∂x2 = x2 - x1\n",
        "#\n",
        "# Conditions:\n",
        "#   - We require that the gradient update rule holds:\n",
        "#         new_point = current_point - learning_rate * gradient\n",
        "#   - The algorithm will stop if the gradient's norm is less than a tolerance level.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define the objective function\n",
        "def f(x):\n",
        "    # x is a numpy array: x[0] = x1, x[1] = x2\n",
        "    return (3/2)*x[0]**2 + (1/2)*x[1]**2 - x[0]*x[1] - 2*x[0]\n",
        "\n",
        "# Define the gradient of the objective function\n",
        "def grad_f(x):\n",
        "    # Compute partial derivatives:\n",
        "    # ∂f/∂x1 = 3*x1 - x2 - 2\n",
        "    # ∂f/∂x2 = x2 - x1\n",
        "    df_dx1 = 3*x[0] - x[1] - 2\n",
        "    df_dx2 = x[1] - x[0]\n",
        "    return np.array([df_dx1, df_dx2])\n",
        "\n",
        "# Print out the functions for clarity\n",
        "print(\"Objective function: f(x1, x2) = (3/2)*x1^2 + (1/2)*x2^2 - x1*x2 - 2*x1\")\n",
        "print(\"Gradient: [3*x1 - x2 - 2, x2 - x1]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nta7YpZZyhhy",
        "outputId": "f578748a-b17f-4a15-ef9e-b524b8e7667c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objective function: f(x1, x2) = (3/2)*x1^2 + (1/2)*x2^2 - x1*x2 - 2*x1\n",
            "Gradient: [3*x1 - x2 - 2, x2 - x1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Set Initial Parameters and Conditions for Gradient Descent\n",
        "# --------------------------------------------------------------------\n",
        "# Here, we set:\n",
        "#   - The initial starting point (x1, x2) = (-2, 4) as given.\n",
        "#   - The learning rate (step size), tolerance (for convergence), and maximum iterations.\n",
        "#\n",
        "# Conditions:\n",
        "#   - The algorithm will stop when the norm of the gradient is below the tolerance.\n",
        "#   - A maximum iteration count is set to prevent infinite loops.\n",
        "\n",
        "# Initial starting point (x1, x2) = (-2, 4)\n",
        "x_current = np.array([-2.0, 4.0])\n",
        "\n",
        "# Learning rate (step size)\n",
        "alpha = 0.1\n",
        "\n",
        "# Tolerance for convergence (if the norm of the gradient is below this value, we stop)\n",
        "tolerance = 1e-6\n",
        "\n",
        "# Maximum number of iterations to prevent infinite loops\n",
        "max_iterations = 1000\n",
        "\n",
        "# Print initial parameters\n",
        "print(\"Initial Point: \", x_current)\n",
        "print(\"Learning Rate (alpha):\", alpha)\n",
        "print(\"Tolerance:\", tolerance)\n",
        "print(\"Maximum Iterations:\", max_iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CojSRBx3yhNe",
        "outputId": "c6b70537-1797-4833-cb97-88cb7863146c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Point:  [-2.  4.]\n",
            "Learning Rate (alpha): 0.1\n",
            "Tolerance: 1e-06\n",
            "Maximum Iterations: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Execute the Gradient Descent Loop\n",
        "# ------------------------------------------\n",
        "# In this step, we:\n",
        "#   - Compute the gradient at the current point.\n",
        "#   - Update the current point using the rule:\n",
        "#         new_point = current_point - alpha * gradient\n",
        "#   - Check the stopping condition: If the norm of the gradient is less than the tolerance, we break.\n",
        "#\n",
        "# Conditions in each iteration:\n",
        "#   1. Compute the gradient: grad = grad_f(x_current)\n",
        "#   2. Check if ||grad|| < tolerance.\n",
        "#   3. Update: x_next = x_current - alpha * grad.\n",
        "#   4. Stop if maximum iterations are reached.\n",
        "\n",
        "# Initialize iteration counter and history for debugging\n",
        "iteration = 0\n",
        "history = [x_current.copy()]\n",
        "\n",
        "while iteration < max_iterations:\n",
        "    # Compute the gradient at the current point\n",
        "    grad = grad_f(x_current)\n",
        "\n",
        "    # Condition: Check if the norm of the gradient is less than the tolerance\n",
        "    grad_norm = np.linalg.norm(grad)\n",
        "    if grad_norm < tolerance:\n",
        "        print(f\"Convergence reached at iteration {iteration}. Norm of gradient = {grad_norm:.2e}\")\n",
        "        break\n",
        "\n",
        "    # Update step: x_new = x_current - alpha * grad\n",
        "    x_new = x_current - alpha * grad\n",
        "\n",
        "    # Debug: Print iteration details\n",
        "    print(f\"Iteration {iteration}: x = {x_current}, f(x) = {f(x_current):.6f}, ||grad|| = {grad_norm:.6f}\")\n",
        "\n",
        "    # Prepare for next iteration\n",
        "    x_current = x_new\n",
        "    history.append(x_current.copy())\n",
        "    iteration += 1\n",
        "\n",
        "# If maximum iterations reached without convergence, print a warning\n",
        "if iteration == max_iterations:\n",
        "    print(\"Warning: Maximum iterations reached without convergence.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFWvQhWfyhIB",
        "outputId": "6fb0d396-de33-4dd4-9165-b4bf31a5b84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: x = [-2.  4.], f(x) = 26.000000, ||grad|| = 13.416408\n",
            "Iteration 1: x = [-0.8  3.4], f(x) = 11.060000, ||grad|| = 8.858894\n",
            "Iteration 2: x = [-0.02  2.98], f(x) = 4.540400, ||grad|| = 5.865288\n",
            "Iteration 3: x = [0.484 2.68 ], f(x) = 1.677464, ||grad|| = 3.904152\n",
            "Iteration 4: x = [0.8068 2.4604], f(x) = 0.404523, ||grad|| = 2.626022\n",
            "Iteration 5: x = [1.0108  2.29504], f(x) = -0.175247, ||grad|| = 1.800981\n",
            "Iteration 6: x = [1.137064 2.166616], f(x) = -0.451225, ||grad|| = 1.276966\n",
            "Iteration 7: x = [1.2126064 2.0636608], f(x) = -0.592652, ||grad|| = 0.951648\n",
            "Iteration 8: x = [1.25519056 1.97855536], f(x) = -0.673249, ||grad|| = 0.754068\n",
            "Iteration 9: x = [1.27648893 1.90621888], f(x) = -0.725274, ||grad|| = 0.634390\n",
            "Iteration 10: x = [1.28416414 1.84324588], f(x) = -0.762965, ||grad|| = 0.559158\n",
            "Iteration 11: x = [1.28323948 1.78733771], f(x) = -0.792718, ||grad|| = 0.507943\n",
            "Iteration 12: x = [1.27700141 1.73692789], f(x) = -0.817504, ||grad|| = 0.469449\n",
            "Iteration 13: x = [1.26759378 1.69093524], f(x) = -0.838785, ||grad|| = 0.437867\n",
            "Iteration 14: x = [1.25640917 1.64860109], f(x) = -0.857347, ||grad|| = 0.410323\n",
            "Iteration 15: x = [1.24434653 1.6093819 ], f(x) = -0.873669, ||grad|| = 0.385412\n",
            "Iteration 16: x = [1.23198076 1.57287836], f(x) = -0.888079, ||grad|| = 0.362431\n",
            "Iteration 17: x = [1.21967437 1.5387886 ], f(x) = -0.900826, ||grad|| = 0.341014\n",
            "Iteration 18: x = [1.20765092 1.50687718], f(x) = -0.912113, ||grad|| = 0.320952\n",
            "Iteration 19: x = [1.19604336 1.47695455], f(x) = -0.922111, ||grad|| = 0.302111\n",
            "Iteration 20: x = [1.18492581 1.44886343], f(x) = -0.930971, ||grad|| = 0.284396\n",
            "Iteration 21: x = [1.17433441 1.42246967], f(x) = -0.938822, ||grad|| = 0.267728\n",
            "Iteration 22: x = [1.16428105 1.39765614], f(x) = -0.945780, ||grad|| = 0.252041\n",
            "Iteration 23: x = [1.15476235 1.37431864], f(x) = -0.951946, ||grad|| = 0.237275\n",
            "Iteration 24: x = [1.14576551 1.35236301], f(x) = -0.957411, ||grad|| = 0.223375\n",
            "Iteration 25: x = [1.13727216 1.33170326], f(x) = -0.962255, ||grad|| = 0.210289\n",
            "Iteration 26: x = [1.12926084 1.31226015], f(x) = -0.966547, ||grad|| = 0.197971\n",
            "Iteration 27: x = [1.1217086  1.29396022], f(x) = -0.970352, ||grad|| = 0.186374\n",
            "Iteration 28: x = [1.11459204 1.27673505], f(x) = -0.973723, ||grad|| = 0.175456\n",
            "Iteration 29: x = [1.10788793 1.26052075], f(x) = -0.976712, ||grad|| = 0.165178\n",
            "Iteration 30: x = [1.10157363 1.24525747], f(x) = -0.979360, ||grad|| = 0.155502\n",
            "Iteration 31: x = [1.09562729 1.23088909], f(x) = -0.981708, ||grad|| = 0.146393\n",
            "Iteration 32: x = [1.09002801 1.21736291], f(x) = -0.983788, ||grad|| = 0.137818\n",
            "Iteration 33: x = [1.0847559  1.20462942], f(x) = -0.985632, ||grad|| = 0.129744\n",
            "Iteration 34: x = [1.07979207 1.19264207], f(x) = -0.987266, ||grad|| = 0.122144\n",
            "Iteration 35: x = [1.07511866 1.18135707], f(x) = -0.988714, ||grad|| = 0.114989\n",
            "Iteration 36: x = [1.07071877 1.17073323], f(x) = -0.989997, ||grad|| = 0.108253\n",
            "Iteration 37: x = [1.06657646 1.16073178], f(x) = -0.991135, ||grad|| = 0.101912\n",
            "Iteration 38: x = [1.0626767  1.15131625], f(x) = -0.992143, ||grad|| = 0.095942\n",
            "Iteration 39: x = [1.05900531 1.14245229], f(x) = -0.993037, ||grad|| = 0.090322\n",
            "Iteration 40: x = [1.05554895 1.13410759], f(x) = -0.993829, ||grad|| = 0.085031\n",
            "Iteration 41: x = [1.05229502 1.12625173], f(x) = -0.994530, ||grad|| = 0.080050\n",
            "Iteration 42: x = [1.04923169 1.11885606], f(x) = -0.995152, ||grad|| = 0.075361\n",
            "Iteration 43: x = [1.04634779 1.11189362], f(x) = -0.995704, ||grad|| = 0.070946\n",
            "Iteration 44: x = [1.04363281 1.10533904], f(x) = -0.996192, ||grad|| = 0.066790\n",
            "Iteration 45: x = [1.04107687 1.09916842], f(x) = -0.996625, ||grad|| = 0.062878\n",
            "Iteration 46: x = [1.03867065 1.09335926], f(x) = -0.997009, ||grad|| = 0.059194\n",
            "Iteration 47: x = [1.03640538 1.0878904 ], f(x) = -0.997349, ||grad|| = 0.055727\n",
            "Iteration 48: x = [1.03427281 1.0827419 ], f(x) = -0.997651, ||grad|| = 0.052463\n",
            "Iteration 49: x = [1.03226516 1.07789499], f(x) = -0.997918, ||grad|| = 0.049389\n",
            "Iteration 50: x = [1.03037511 1.07333201], f(x) = -0.998155, ||grad|| = 0.046496\n",
            "Iteration 51: x = [1.02859578 1.06903632], f(x) = -0.998365, ||grad|| = 0.043773\n",
            "Iteration 52: x = [1.02692068 1.06499226], f(x) = -0.998551, ||grad|| = 0.041208\n",
            "Iteration 53: x = [1.0253437 1.0611851], f(x) = -0.998715, ||grad|| = 0.038794\n",
            "Iteration 54: x = [1.0238591  1.05760096], f(x) = -0.998861, ||grad|| = 0.036522\n",
            "Iteration 55: x = [1.02246147 1.05422678], f(x) = -0.998991, ||grad|| = 0.034383\n",
            "Iteration 56: x = [1.0211457  1.05105025], f(x) = -0.999106, ||grad|| = 0.032368\n",
            "Iteration 57: x = [1.01990702 1.04805979], f(x) = -0.999207, ||grad|| = 0.030472\n",
            "Iteration 58: x = [1.01874089 1.04524451], f(x) = -0.999298, ||grad|| = 0.028687\n",
            "Iteration 59: x = [1.01764308 1.04259415], f(x) = -0.999377, ||grad|| = 0.027007\n",
            "Iteration 60: x = [1.01660957 1.04009904], f(x) = -0.999448, ||grad|| = 0.025425\n",
            "Iteration 61: x = [1.0156366 1.0377501], f(x) = -0.999511, ||grad|| = 0.023935\n",
            "Iteration 62: x = [1.01472063 1.03553875], f(x) = -0.999567, ||grad|| = 0.022533\n",
            "Iteration 63: x = [1.01385832 1.03345694], f(x) = -0.999616, ||grad|| = 0.021213\n",
            "Iteration 64: x = [1.01304652 1.03149707], f(x) = -0.999660, ||grad|| = 0.019971\n",
            "Iteration 65: x = [1.01228227 1.02965202], f(x) = -0.999698, ||grad|| = 0.018801\n",
            "Iteration 66: x = [1.01156279 1.02791504], f(x) = -0.999733, ||grad|| = 0.017700\n",
            "Iteration 67: x = [1.01088546 1.02627982], f(x) = -0.999763, ||grad|| = 0.016663\n",
            "Iteration 68: x = [1.0102478  1.02474038], f(x) = -0.999790, ||grad|| = 0.015687\n",
            "Iteration 69: x = [1.0096475  1.02329112], f(x) = -0.999814, ||grad|| = 0.014768\n",
            "Iteration 70: x = [1.00908236 1.02192676], f(x) = -0.999835, ||grad|| = 0.013903\n",
            "Iteration 71: x = [1.00855033 1.02064232], f(x) = -0.999854, ||grad|| = 0.013088\n",
            "Iteration 72: x = [1.00804946 1.01943312], f(x) = -0.999870, ||grad|| = 0.012322\n",
            "Iteration 73: x = [1.00757794 1.01829476], f(x) = -0.999885, ||grad|| = 0.011600\n",
            "Iteration 74: x = [1.00713403 1.01722307], f(x) = -0.999898, ||grad|| = 0.010920\n",
            "Iteration 75: x = [1.00671613 1.01621417], f(x) = -0.999910, ||grad|| = 0.010281\n",
            "Iteration 76: x = [1.00632271 1.01526437], f(x) = -0.999920, ||grad|| = 0.009678\n",
            "Iteration 77: x = [1.00595233 1.0143702 ], f(x) = -0.999929, ||grad|| = 0.009111\n",
            "Iteration 78: x = [1.00560365 1.01352841], f(x) = -0.999937, ||grad|| = 0.008578\n",
            "Iteration 79: x = [1.0052754  1.01273594], f(x) = -0.999944, ||grad|| = 0.008075\n",
            "Iteration 80: x = [1.00496637 1.01198988], f(x) = -0.999951, ||grad|| = 0.007602\n",
            "Iteration 81: x = [1.00467545 1.01128753], f(x) = -0.999956, ||grad|| = 0.007157\n",
            "Iteration 82: x = [1.00440157 1.01062632], f(x) = -0.999961, ||grad|| = 0.006738\n",
            "Iteration 83: x = [1.00414373 1.01000385], f(x) = -0.999966, ||grad|| = 0.006343\n",
            "Iteration 84: x = [1.003901   1.00941784], f(x) = -0.999970, ||grad|| = 0.005971\n",
            "Iteration 85: x = [1.00367248 1.00886615], f(x) = -0.999973, ||grad|| = 0.005622\n",
            "Iteration 86: x = [1.00345735 1.00834678], f(x) = -0.999976, ||grad|| = 0.005292\n",
            "Iteration 87: x = [1.00325482 1.00785784], f(x) = -0.999979, ||grad|| = 0.004982\n",
            "Iteration 88: x = [1.00306416 1.00739754], f(x) = -0.999981, ||grad|| = 0.004690\n",
            "Iteration 89: x = [1.00288467 1.0069642 ], f(x) = -0.999983, ||grad|| = 0.004416\n",
            "Iteration 90: x = [1.00271569 1.00655625], f(x) = -0.999985, ||grad|| = 0.004157\n",
            "Iteration 91: x = [1.00255661 1.00617219], f(x) = -0.999987, ||grad|| = 0.003913\n",
            "Iteration 92: x = [1.00240684 1.00581063], f(x) = -0.999988, ||grad|| = 0.003684\n",
            "Iteration 93: x = [1.00226585 1.00547025], f(x) = -0.999990, ||grad|| = 0.003468\n",
            "Iteration 94: x = [1.00213312 1.00514981], f(x) = -0.999991, ||grad|| = 0.003265\n",
            "Iteration 95: x = [1.00200817 1.00484815], f(x) = -0.999992, ||grad|| = 0.003074\n",
            "Iteration 96: x = [1.00189053 1.00456415], f(x) = -0.999993, ||grad|| = 0.002894\n",
            "Iteration 97: x = [1.00177979 1.00429679], f(x) = -0.999994, ||grad|| = 0.002724\n",
            "Iteration 98: x = [1.00167553 1.00404509], f(x) = -0.999994, ||grad|| = 0.002565\n",
            "Iteration 99: x = [1.00157738 1.00380813], f(x) = -0.999995, ||grad|| = 0.002415\n",
            "Iteration 100: x = [1.00148498 1.00358506], f(x) = -0.999996, ||grad|| = 0.002273\n",
            "Iteration 101: x = [1.00139799 1.00337505], f(x) = -0.999996, ||grad|| = 0.002140\n",
            "Iteration 102: x = [1.0013161  1.00317734], f(x) = -0.999997, ||grad|| = 0.002015\n",
            "Iteration 103: x = [1.001239   1.00299122], f(x) = -0.999997, ||grad|| = 0.001897\n",
            "Iteration 104: x = [1.00116642 1.002816  ], f(x) = -0.999997, ||grad|| = 0.001785\n",
            "Iteration 105: x = [1.0010981  1.00265104], f(x) = -0.999998, ||grad|| = 0.001681\n",
            "Iteration 106: x = [1.00103377 1.00249574], f(x) = -0.999998, ||grad|| = 0.001582\n",
            "Iteration 107: x = [1.00097321 1.00234955], f(x) = -0.999998, ||grad|| = 0.001490\n",
            "Iteration 108: x = [1.0009162  1.00221191], f(x) = -0.999998, ||grad|| = 0.001402\n",
            "Iteration 109: x = [1.00086253 1.00208234], f(x) = -0.999999, ||grad|| = 0.001320\n",
            "Iteration 110: x = [1.00081201 1.00196036], f(x) = -0.999999, ||grad|| = 0.001243\n",
            "Iteration 111: x = [1.00076444 1.00184553], f(x) = -0.999999, ||grad|| = 0.001170\n",
            "Iteration 112: x = [1.00071966 1.00173742], f(x) = -0.999999, ||grad|| = 0.001102\n",
            "Iteration 113: x = [1.00067751 1.00163564], f(x) = -0.999999, ||grad|| = 0.001037\n",
            "Iteration 114: x = [1.00063782 1.00153983], f(x) = -0.999999, ||grad|| = 0.000976\n",
            "Iteration 115: x = [1.00060046 1.00144963], f(x) = -0.999999, ||grad|| = 0.000919\n",
            "Iteration 116: x = [1.00056528 1.00136471], f(x) = -0.999999, ||grad|| = 0.000865\n",
            "Iteration 117: x = [1.00053217 1.00128477], f(x) = -0.999999, ||grad|| = 0.000815\n",
            "Iteration 118: x = [1.00050099 1.00120951], f(x) = -0.999999, ||grad|| = 0.000767\n",
            "Iteration 119: x = [1.00047165 1.00113866], f(x) = -1.000000, ||grad|| = 0.000722\n",
            "Iteration 120: x = [1.00044402 1.00107196], f(x) = -1.000000, ||grad|| = 0.000680\n",
            "Iteration 121: x = [1.00041801 1.00100916], f(x) = -1.000000, ||grad|| = 0.000640\n",
            "Iteration 122: x = [1.00039352 1.00095005], f(x) = -1.000000, ||grad|| = 0.000602\n",
            "Iteration 123: x = [1.00037047 1.00089439], f(x) = -1.000000, ||grad|| = 0.000567\n",
            "Iteration 124: x = [1.00034877 1.000842  ], f(x) = -1.000000, ||grad|| = 0.000534\n",
            "Iteration 125: x = [1.00032834 1.00079268], f(x) = -1.000000, ||grad|| = 0.000503\n",
            "Iteration 126: x = [1.0003091  1.00074624], f(x) = -1.000000, ||grad|| = 0.000473\n",
            "Iteration 127: x = [1.000291   1.00070253], f(x) = -1.000000, ||grad|| = 0.000445\n",
            "Iteration 128: x = [1.00027395 1.00066138], f(x) = -1.000000, ||grad|| = 0.000419\n",
            "Iteration 129: x = [1.0002579  1.00062263], f(x) = -1.000000, ||grad|| = 0.000395\n",
            "Iteration 130: x = [1.0002428  1.00058616], f(x) = -1.000000, ||grad|| = 0.000372\n",
            "Iteration 131: x = [1.00022857 1.00055182], f(x) = -1.000000, ||grad|| = 0.000350\n",
            "Iteration 132: x = [1.00021518 1.0005195 ], f(x) = -1.000000, ||grad|| = 0.000329\n",
            "Iteration 133: x = [1.00020258 1.00048907], f(x) = -1.000000, ||grad|| = 0.000310\n",
            "Iteration 134: x = [1.00019071 1.00046042], f(x) = -1.000000, ||grad|| = 0.000292\n",
            "Iteration 135: x = [1.00017954 1.00043345], f(x) = -1.000000, ||grad|| = 0.000275\n",
            "Iteration 136: x = [1.00016902 1.00040806], f(x) = -1.000000, ||grad|| = 0.000259\n",
            "Iteration 137: x = [1.00015912 1.00038415], f(x) = -1.000000, ||grad|| = 0.000244\n",
            "Iteration 138: x = [1.0001498  1.00036165], f(x) = -1.000000, ||grad|| = 0.000229\n",
            "Iteration 139: x = [1.00014103 1.00034047], f(x) = -1.000000, ||grad|| = 0.000216\n",
            "Iteration 140: x = [1.00013276 1.00032052], f(x) = -1.000000, ||grad|| = 0.000203\n",
            "Iteration 141: x = [1.00012499 1.00030175], f(x) = -1.000000, ||grad|| = 0.000191\n",
            "Iteration 142: x = [1.00011767 1.00028407], f(x) = -1.000000, ||grad|| = 0.000180\n",
            "Iteration 143: x = [1.00011077 1.00026743], f(x) = -1.000000, ||grad|| = 0.000170\n",
            "Iteration 144: x = [1.00010428 1.00025176], f(x) = -1.000000, ||grad|| = 0.000160\n",
            "Iteration 145: x = [1.00009818 1.00023702], f(x) = -1.000000, ||grad|| = 0.000150\n",
            "Iteration 146: x = [1.00009242 1.00022313], f(x) = -1.000000, ||grad|| = 0.000141\n",
            "Iteration 147: x = [1.00008701 1.00021006], f(x) = -1.000000, ||grad|| = 0.000133\n",
            "Iteration 148: x = [1.00008191 1.00019776], f(x) = -1.000000, ||grad|| = 0.000125\n",
            "Iteration 149: x = [1.00007711 1.00018617], f(x) = -1.000000, ||grad|| = 0.000118\n",
            "Iteration 150: x = [1.0000726  1.00017527], f(x) = -1.000000, ||grad|| = 0.000111\n",
            "Iteration 151: x = [1.00006834 1.000165  ], f(x) = -1.000000, ||grad|| = 0.000105\n",
            "Iteration 152: x = [1.00006434 1.00015533], f(x) = -1.000000, ||grad|| = 0.000098\n",
            "Iteration 153: x = [1.00006057 1.00014623], f(x) = -1.000000, ||grad|| = 0.000093\n",
            "Iteration 154: x = [1.00005702 1.00013767], f(x) = -1.000000, ||grad|| = 0.000087\n",
            "Iteration 155: x = [1.00005368 1.0001296 ], f(x) = -1.000000, ||grad|| = 0.000082\n",
            "Iteration 156: x = [1.00005054 1.00012201], f(x) = -1.000000, ||grad|| = 0.000077\n",
            "Iteration 157: x = [1.00004758 1.00011486], f(x) = -1.000000, ||grad|| = 0.000073\n",
            "Iteration 158: x = [1.00004479 1.00010814], f(x) = -1.000000, ||grad|| = 0.000069\n",
            "Iteration 159: x = [1.00004217 1.0001018 ], f(x) = -1.000000, ||grad|| = 0.000065\n",
            "Iteration 160: x = [1.0000397  1.00009584], f(x) = -1.000000, ||grad|| = 0.000061\n",
            "Iteration 161: x = [1.00003737 1.00009022], f(x) = -1.000000, ||grad|| = 0.000057\n",
            "Iteration 162: x = [1.00003518 1.00008494], f(x) = -1.000000, ||grad|| = 0.000054\n",
            "Iteration 163: x = [1.00003312 1.00007996], f(x) = -1.000000, ||grad|| = 0.000051\n",
            "Iteration 164: x = [1.00003118 1.00007528], f(x) = -1.000000, ||grad|| = 0.000048\n",
            "Iteration 165: x = [1.00002936 1.00007087], f(x) = -1.000000, ||grad|| = 0.000045\n",
            "Iteration 166: x = [1.00002764 1.00006672], f(x) = -1.000000, ||grad|| = 0.000042\n",
            "Iteration 167: x = [1.00002602 1.00006281], f(x) = -1.000000, ||grad|| = 0.000040\n",
            "Iteration 168: x = [1.00002449 1.00005913], f(x) = -1.000000, ||grad|| = 0.000037\n",
            "Iteration 169: x = [1.00002306 1.00005567], f(x) = -1.000000, ||grad|| = 0.000035\n",
            "Iteration 170: x = [1.00002171 1.00005241], f(x) = -1.000000, ||grad|| = 0.000033\n",
            "Iteration 171: x = [1.00002044 1.00004934], f(x) = -1.000000, ||grad|| = 0.000031\n",
            "Iteration 172: x = [1.00001924 1.00004645], f(x) = -1.000000, ||grad|| = 0.000029\n",
            "Iteration 173: x = [1.00001811 1.00004373], f(x) = -1.000000, ||grad|| = 0.000028\n",
            "Iteration 174: x = [1.00001705 1.00004116], f(x) = -1.000000, ||grad|| = 0.000026\n",
            "Iteration 175: x = [1.00001605 1.00003875], f(x) = -1.000000, ||grad|| = 0.000025\n",
            "Iteration 176: x = [1.00001511 1.00003648], f(x) = -1.000000, ||grad|| = 0.000023\n",
            "Iteration 177: x = [1.00001423 1.00003435], f(x) = -1.000000, ||grad|| = 0.000022\n",
            "Iteration 178: x = [1.00001339 1.00003233], f(x) = -1.000000, ||grad|| = 0.000021\n",
            "Iteration 179: x = [1.00001261 1.00003044], f(x) = -1.000000, ||grad|| = 0.000019\n",
            "Iteration 180: x = [1.00001187 1.00002866], f(x) = -1.000000, ||grad|| = 0.000018\n",
            "Iteration 181: x = [1.00001117 1.00002698], f(x) = -1.000000, ||grad|| = 0.000017\n",
            "Iteration 182: x = [1.00001052 1.0000254 ], f(x) = -1.000000, ||grad|| = 0.000016\n",
            "Iteration 183: x = [1.0000099  1.00002391], f(x) = -1.000000, ||grad|| = 0.000015\n",
            "Iteration 184: x = [1.00000932 1.00002251], f(x) = -1.000000, ||grad|| = 0.000014\n",
            "Iteration 185: x = [1.00000878 1.00002119], f(x) = -1.000000, ||grad|| = 0.000013\n",
            "Iteration 186: x = [1.00000826 1.00001995], f(x) = -1.000000, ||grad|| = 0.000013\n",
            "Iteration 187: x = [1.00000778 1.00001878], f(x) = -1.000000, ||grad|| = 0.000012\n",
            "Iteration 188: x = [1.00000732 1.00001768], f(x) = -1.000000, ||grad|| = 0.000011\n",
            "Iteration 189: x = [1.00000689 1.00001664], f(x) = -1.000000, ||grad|| = 0.000011\n",
            "Iteration 190: x = [1.00000649 1.00001567], f(x) = -1.000000, ||grad|| = 0.000010\n",
            "Iteration 191: x = [1.00000611 1.00001475], f(x) = -1.000000, ||grad|| = 0.000009\n",
            "Iteration 192: x = [1.00000575 1.00001389], f(x) = -1.000000, ||grad|| = 0.000009\n",
            "Iteration 193: x = [1.00000542 1.00001307], f(x) = -1.000000, ||grad|| = 0.000008\n",
            "Iteration 194: x = [1.0000051  1.00001231], f(x) = -1.000000, ||grad|| = 0.000008\n",
            "Iteration 195: x = [1.0000048  1.00001159], f(x) = -1.000000, ||grad|| = 0.000007\n",
            "Iteration 196: x = [1.00000452 1.00001091], f(x) = -1.000000, ||grad|| = 0.000007\n",
            "Iteration 197: x = [1.00000425 1.00001027], f(x) = -1.000000, ||grad|| = 0.000007\n",
            "Iteration 198: x = [1.000004   1.00000967], f(x) = -1.000000, ||grad|| = 0.000006\n",
            "Iteration 199: x = [1.00000377 1.0000091 ], f(x) = -1.000000, ||grad|| = 0.000006\n",
            "Iteration 200: x = [1.00000355 1.00000857], f(x) = -1.000000, ||grad|| = 0.000005\n",
            "Iteration 201: x = [1.00000334 1.00000807], f(x) = -1.000000, ||grad|| = 0.000005\n",
            "Iteration 202: x = [1.00000315 1.00000759], f(x) = -1.000000, ||grad|| = 0.000005\n",
            "Iteration 203: x = [1.00000296 1.00000715], f(x) = -1.000000, ||grad|| = 0.000005\n",
            "Iteration 204: x = [1.00000279 1.00000673], f(x) = -1.000000, ||grad|| = 0.000004\n",
            "Iteration 205: x = [1.00000262 1.00000634], f(x) = -1.000000, ||grad|| = 0.000004\n",
            "Iteration 206: x = [1.00000247 1.00000596], f(x) = -1.000000, ||grad|| = 0.000004\n",
            "Iteration 207: x = [1.00000233 1.00000562], f(x) = -1.000000, ||grad|| = 0.000004\n",
            "Iteration 208: x = [1.00000219 1.00000529], f(x) = -1.000000, ||grad|| = 0.000003\n",
            "Iteration 209: x = [1.00000206 1.00000498], f(x) = -1.000000, ||grad|| = 0.000003\n",
            "Iteration 210: x = [1.00000194 1.00000469], f(x) = -1.000000, ||grad|| = 0.000003\n",
            "Iteration 211: x = [1.00000183 1.00000441], f(x) = -1.000000, ||grad|| = 0.000003\n",
            "Iteration 212: x = [1.00000172 1.00000415], f(x) = -1.000000, ||grad|| = 0.000003\n",
            "Iteration 213: x = [1.00000162 1.00000391], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 214: x = [1.00000152 1.00000368], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 215: x = [1.00000144 1.00000346], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 216: x = [1.00000135 1.00000326], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 217: x = [1.00000127 1.00000307], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 218: x = [1.0000012  1.00000289], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 219: x = [1.00000113 1.00000272], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 220: x = [1.00000106 1.00000256], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 221: x = [1.000001   1.00000241], f(x) = -1.000000, ||grad|| = 0.000002\n",
            "Iteration 222: x = [1.00000094 1.00000227], f(x) = -1.000000, ||grad|| = 0.000001\n",
            "Iteration 223: x = [1.00000089 1.00000214], f(x) = -1.000000, ||grad|| = 0.000001\n",
            "Iteration 224: x = [1.00000083 1.00000201], f(x) = -1.000000, ||grad|| = 0.000001\n",
            "Iteration 225: x = [1.00000078 1.00000189], f(x) = -1.000000, ||grad|| = 0.000001\n",
            "Iteration 226: x = [1.00000074 1.00000178], f(x) = -1.000000, ||grad|| = 0.000001\n",
            "Iteration 227: x = [1.0000007  1.00000168], f(x) = -1.000000, ||grad|| = 0.000001\n",
            "Iteration 228: x = [1.00000065 1.00000158], f(x) = -1.000000, ||grad|| = 0.000001\n",
            "Convergence reached at iteration 229. Norm of gradient = 9.44e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Output the Final Minimum Point and Final Objective Value\n",
        "# ------------------------------------------------------------------\n",
        "# After the loop, the variable x_current contains the approximate minimizer.\n",
        "#\n",
        "# Conditions:\n",
        "#   - The final output is provided only if the gradient norm condition is satisfied.\n",
        "#   - We display the minimal coordinate (x1, x2) and the final objective value f(x1, x2).\n",
        "\n",
        "minimizer = x_current\n",
        "final_value = f(minimizer)\n",
        "\n",
        "print(\"\\nFinal Optimal (Minimizer) Coordinate:\")\n",
        "print(\"x1 =\", minimizer[0], \"(min)\")\n",
        "print(\"x2 =\", minimizer[1], \"(min)\")\n",
        "print(\"Final Objective Function Value: f(x1, x2) =\", final_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb2Dl74Uyg9b",
        "outputId": "f8b19a2c-dd8f-4c0e-9df3-07efb210c0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Optimal (Minimizer) Coordinate:\n",
            "x1 = 1.0000006163992898 (min)\n",
            "x2 = 1.0000014881195254 (min)\n",
            "Final Objective Function Value: f(x1, x2) = -0.9999999999992404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**שאלה 2: הגדרת בעיית אופטימיזציה**"
      ],
      "metadata": {
        "id": "siwoiqXlTAWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages.\n",
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "\n",
        "# Define the 10-dimensional optimization variable x.\n",
        "# We'll refer to its elements as x[0] (x1), x[1] (x2), ..., x[9] (x10).\n",
        "x = cp.Variable(10)"
      ],
      "metadata": {
        "id": "p_SYat11NM8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function:\n",
        "# f(x) = 1/2 * sum_{i=1}^{10} x_i^2 + 3*exp(x1) + 4*sqrt(1+x2^2)\n",
        "# Replace sqrt(1+x2^2) with cp.norm(cp.hstack([1, x[1]]))\n",
        "objective = cp.Minimize(0.5 * cp.sum_squares(x) + 3 * cp.exp(x[0]) + 4 * cp.norm(cp.hstack([1, x[1]])))\n",
        "\n",
        "# Note:\n",
        "# - The quadratic term is convex.\n",
        "# - The exponential term is convex.\n",
        "# - The norm term is convex (and equivalent to sqrt(1+x2^2))."
      ],
      "metadata": {
        "id": "YRFiefbMNM5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constraint 1: Linear sum constraint: x1 + x2 + ... + x10 <= 20\n",
        "constr1 = cp.sum(x) <= 20\n",
        "\n",
        "# Constraint 2: Linear weighted combination: -x1 + 2*x2 - 3*x3 <= 5\n",
        "constr2 = (-x[0] + 2*x[1] - 3*x[2]) <= 5\n",
        "\n",
        "# Constraint 3: Quadratic constraint (Euclidean ball in (x1,x2)): x1^2 + x2^2 <= 16\n",
        "constr3 = cp.square(x[0]) + cp.square(x[1]) <= 16\n",
        "\n",
        "# Constraint 4: Quadratic constraint (shifted ball in (x3,x4)): (x3-1)^2 + (x4-2)^2 <= 9\n",
        "constr4 = cp.square(x[2]-1) + cp.square(x[3]-2) <= 9\n",
        "\n",
        "# Constraint 5: Exponential constraint: exp(x5) <= 10\n",
        "# (x[4] represents x5)\n",
        "constr5 = cp.exp(x[4]) <= 10\n",
        "\n",
        "# Constraint 6: Square-root constraint: sqrt(1+x6^2) <= 2\n",
        "# Replace sqrt(1+x6^2) with cp.norm(cp.hstack([1, x[5]]))\n",
        "constr6 = cp.norm(cp.hstack([1, x[5]])) <= 2\n",
        "\n",
        "# Constraint 7: Box constraints for all variables: -100 <= xi <= 100 for i = 1,...,10\n",
        "constr7 = [x[i] >= -100 for i in range(10)] + [x[i] <= 100 for i in range(10)]\n",
        "\n",
        "# Constraint 8: Euclidean norm constraint for (x9,x10): sqrt(x9^2+x10^2) <= 5\n",
        "# (x[8] is x9 and x[9] is x10)\n",
        "constr8 = cp.norm(x[8:10], 2) <= 5\n",
        "\n",
        "# Combine all constraints into a single list.\n",
        "constraints = [constr1, constr2, constr3, constr4, constr5, constr6, constr8] + constr7"
      ],
      "metadata": {
        "id": "o0weyPjXNM11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and solve the problem.\n",
        "problem = cp.Problem(objective, constraints)\n",
        "\n",
        "# We solve the problem using the SCS solver.\n",
        "# You can also try other solvers like 'ECOS' or 'MOSEK' if available.\n",
        "problem.solve(solver=cp.SCS)\n",
        "\n",
        "# Check that the problem was solved successfully.\n",
        "print(\"Status:\", problem.status)\n",
        "print(\"Optimal Objective Value:\", problem.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHvz0jjVNMyG",
        "outputId": "3f519f4f-2169-4a5a-d187-518947d0848a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status: optimal\n",
            "Optimal Objective Value: 5.601063238826346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the optimal variable values.\n",
        "x_opt = x.value\n",
        "\n",
        "print(\"\\nOptimal Variables (x*):\")\n",
        "for i in range(10):\n",
        "    label = \"\"\n",
        "    # Check if the coordinate is at the box constraint boundary.\n",
        "    if np.isclose(x_opt[i], 100, atol=1e-3):\n",
        "        label = \" (max-bound active)\"\n",
        "    elif np.isclose(x_opt[i], -100, atol=1e-3):\n",
        "        label = \" (min-bound active)\"\n",
        "    print(f\"x[{i+1}] = {x_opt[i]:.4f}{label}\")\n",
        "\n",
        "print(\"\\nLagrange Multipliers (Lambdas):\")\n",
        "\n",
        "# Print dual variables for each constraint.\n",
        "# Note: For each constraint, CVXPY stores the dual value in the attribute 'dual_value'.\n",
        "\n",
        "# Constraint 1: Sum constraint (x1+...+x10 <= 20)\n",
        "lambda1 = constraints[0].dual_value\n",
        "print(f\"Lambda1 (for x1+...+x10 <= 20): {lambda1:.4f}\")\n",
        "\n",
        "# Constraint 2: Weighted linear constraint (-x1+2*x2-3*x3 <= 5)\n",
        "lambda2 = constraints[1].dual_value\n",
        "print(f\"Lambda2 (for -x1+2*x2-3*x3 <= 5): {lambda2:.4f}\")\n",
        "\n",
        "# Constraint 3: Quadratic constraint x1^2+x2^2 <= 16\n",
        "lambda3 = constraints[2].dual_value\n",
        "print(f\"Lambda3 (for x1^2+x2^2 <= 16): {lambda3:.4f}\")\n",
        "\n",
        "# Constraint 4: Shifted quadratic constraint (x3-1)^2+(x4-2)^2 <= 9\n",
        "lambda4 = constraints[3].dual_value\n",
        "print(f\"Lambda4 (for (x3-1)^2+(x4-2)^2 <= 9): {lambda4:.4f}\")\n",
        "\n",
        "# Constraint 5: Exponential constraint exp(x5) <= 10\n",
        "lambda5 = constraints[4].dual_value\n",
        "print(f\"Lambda5 (for exp(x5) <= 10): {lambda5:.4f}\")\n",
        "\n",
        "# Constraint 6: Norm constraint cp.norm([1, x6]) <= 2 (equivalent to sqrt(1+x6^2) <= 2)\n",
        "lambda6 = constraints[5].dual_value\n",
        "print(f\"Lambda6 (for cp.norm([1, x6]) <= 2): {lambda6:.4f}\")\n",
        "\n",
        "# Constraint 8: Euclidean norm constraint for (x9,x10): norm(x9,x10) <= 5\n",
        "lambda8 = constraints[6].dual_value\n",
        "print(f\"Lambda8 (for norm(x9,x10) <= 5): {lambda8:.4f}\")\n",
        "\n",
        "# Constraint 7: Box constraints for each xi: -100 <= xi <= 100.\n",
        "# There are 20 constraints here: 10 for the lower bound and 10 for the upper bound.\n",
        "# We print the dual values if any are active (i.e., nonzero).\n",
        "for i in range(10):\n",
        "    lambda_lower = constraints[7+i].dual_value\n",
        "    if abs(lambda_lower) > 1e-6:\n",
        "        print(f\"Lambda7_lower for x[{i+1}] >= -100: {lambda_lower:.4f}\")\n",
        "for i in range(10):\n",
        "    lambda_upper = constraints[7+10+i].dual_value\n",
        "    if abs(lambda_upper) > 1e-6:\n",
        "        print(f\"Lambda7_upper for x[{i+1}] <= 100: {lambda_upper:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NsG64GgNMue",
        "outputId": "9af7e8b4-9bc7-4d2a-b4ff-04d55afaec5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal Variables (x*):\n",
            "x[1] = -1.0499\n",
            "x[2] = 0.0000\n",
            "x[3] = 0.0000\n",
            "x[4] = 0.0000\n",
            "x[5] = 0.0000\n",
            "x[6] = 0.0000\n",
            "x[7] = 0.0000\n",
            "x[8] = 0.0000\n",
            "x[9] = 0.0000\n",
            "x[10] = 0.0000\n",
            "\n",
            "Lagrange Multipliers (Lambdas):\n",
            "Lambda1 (for x1+...+x10 <= 20): 0.0000\n",
            "Lambda2 (for -x1+2*x2-3*x3 <= 5): 0.0000\n",
            "Lambda3 (for x1^2+x2^2 <= 16): 0.0000\n",
            "Lambda4 (for (x3-1)^2+(x4-2)^2 <= 9): 0.0000\n",
            "Lambda5 (for exp(x5) <= 10): 0.0000\n",
            "Lambda6 (for cp.norm([1, x6]) <= 2): 0.0000\n",
            "Lambda8 (for norm(x9,x10) <= 5): 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the final optimal objective function value.\n",
        "print(\"\\nFinal Optimal Objective Value:\", problem.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzT5AjNvNMqW",
        "outputId": "fbdf93ce-8f60-4e41-fa95-87ea42a3d16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Optimal Objective Value: 5.601063238826346\n"
          ]
        }
      ]
    }
  ]
}